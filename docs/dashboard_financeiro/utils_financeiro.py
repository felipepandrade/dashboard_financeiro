"""
utils_financeiro.py
===================
Utilit√°rios focados em an√°lise financeira: ETL, valida√ß√£o, forecasting e IA.

Autor: Sistema de An√°lise Financeira
Vers√£o: 2.0.0 (Standalone)
"""

# =============================================================================
# 1. IMPORTA√á√ïES
# =============================================================================

# --- Padr√£o e Sistema ---
from typing import List, Tuple, Dict, Optional, Union
from datetime import datetime, timedelta
from io import BytesIO
import warnings
import os

import pandas as pd
import numpy as np
import streamlit as st
from database.models import RazaoRealizado, get_session, get_engine
from sqlalchemy import text

# --- Valida√ß√£o de Dados ---
import pandera as pa
from pandera import Column, Check, DataFrameSchema

# --- An√°lise de S√©rie Temporal ---
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
import matplotlib.pyplot as plt

# --- Visualiza√ß√£o ---
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- IA e ML ---
import google.generativeai as genai
from openai import OpenAI
from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error
from sklearn.linear_model import LinearRegression

warnings.filterwarnings('ignore')

# =============================================================================
# 2. CONFIGURA√á√ïES GLOBAIS
# =============================================================================

ABAS_PROCESSAR = [
    'ITABUNA', 'CAMA√áARI', 'CATU', 'ECOMP CATU', 'ATALAIA', 'PILAR'
]

MESES_ORDEM = ['JAN', 'FEV', 'MAR', 'ABR', 'MAI', 'JUN',
               'JUL', 'AGO', 'SET', 'OUT', 'NOV', 'DEZ']

MESES_NUM_MAP = {mes: i+1 for i, mes in enumerate(MESES_ORDEM)}

# =============================================================================
# 3. FUN√á√ïES DE ETL FINANCEIRO
# =============================================================================

def _standardize_string(text):
    """
    Normaliza uma string: converte para min√∫sculas, remove acentos,
    caracteres especiais e substitui espa√ßos por underscores.
    """
    import unicodedata
    import re
    if pd.isna(text):
        return ""
    text_str = str(text)
    normalized_text = unicodedata.normalize('NFD', text_str).encode('ascii', 'ignore').decode('utf-8')
    clean_text = re.sub(r'[^a-zA-Z0-9\s]', '', normalized_text.lower().strip())
    return re.sub(r'\s+', '_', clean_text)


def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """Aplica padroniza√ß√£o de strings a todos os nomes de colunas."""
    if df is None or df.empty:
        return df
    df.columns = [_standardize_string(col) for col in df.columns]
    return df


@st.cache_data(show_spinner="Processando Arquivo Financeiro Completo...")
def processar_upload_completo(uploaded_file, ano: int = None) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Processa o arquivo Excel financeiro, extraindo P&L e Raz√£o de Gastos.
    
    Args:
        uploaded_file: Arquivo Excel
        ano: Ano de refer√™ncia
        
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: (df_pl, df_razao)
    """
    if not uploaded_file:
        return pd.DataFrame(), pd.DataFrame()
    
    if ano is None:
        ano = datetime.now().year
    
    # -------------------------------------------------------------------------
    # 1. PROCESSAR P&L
    # -------------------------------------------------------------------------
    df_pl = pd.DataFrame()
    try:
        if hasattr(uploaded_file, 'seek'): uploaded_file.seek(0)
        df = pd.read_excel(uploaded_file, sheet_name='P&L BASEAL', skiprows=15, header=0)
        df.fillna(0, inplace=True)
        
        # Renomear e limpar
        df.rename(columns={df.columns[0]: 'codigo_centro_gasto', df.columns[2]: 'conta_contabil'}, inplace=True)
        
        contas_financeiras = [
            "Gross Sales - Basic Services", "Gross Sales - Eventual Services",
            "Sales tax - Basic", "Sales tax - Eventual", "Net Revenue",
            "Gross profit", "Gross margin (%)", "Cost of Sales"
        ]
        
        df_custos = df[df['codigo_centro_gasto'] != 0].copy()
        df_financeiro = df[(df['codigo_centro_gasto'] == 0) & (df['conta_contabil'].isin(contas_financeiras))].copy()
        
        df_custos['codigo_centro_gasto'] = (
            df_custos['codigo_centro_gasto'].astype(str)
            .str.replace(r'\.0$', '', regex=True)
            .apply(lambda x: '0' + x if len(x) == 10 else x)
        )
        
        mapa_centro_custo = {
            '01020504001': 'Ger√™ncia Regional BA', '1020504001': 'Ger√™ncia Regional BA',
            '01020504101': 'Coordena√ß√£o Catu', '1020504101': 'Coordena√ß√£o Catu',
            '01020504102': 'ECOMP CATU - BA', '1020504102': 'ECOMP CATU - BA',
            '01020504204': 'BASE CATU - BA', '1020504204': 'BASE CATU - BA',
            '01020504201': 'Coordena√ß√£o Estacion√°rio BA', '1020504201': 'Coordena√ß√£o Estacion√°rio BA',
            '01020504202': 'BASE CAMA√áARI - BA', '1020504202': 'BASE CAMA√áARI - BA',
            '01020504203': 'BASE ITABUNA - BA', '1020504203': 'BASE ITABUNA - BA',
            '01020505201': 'Coordena√ß√£o Estacionar SE/AL', '1020505201': 'Coordena√ß√£o Estacionar SE/AL',
            '01020505202': 'BASE ATALAIA - SE', '1020505202': 'BASE ATALAIA - SE',
            '01020505203': 'BASE PILAR - AL', '1020505203': 'BASE PILAR - AL'
        }
        
        df_custos['centro_gasto_nome'] = df_custos['codigo_centro_gasto'].map(mapa_centro_custo)
        df_processado = pd.concat([df_custos, df_financeiro], ignore_index=True)
        colunas_identificadoras = ['codigo_centro_gasto', 'centro_gasto_nome', 'conta_contabil']
        
        mapa_colunas_mes = {
            'JAN': {3: 'Realizado', 4: 'Budget V1', 6: 'Budget V3', 7: 'LY - Actual'},
            'FEV': {8: 'Realizado', 9: 'Budget V1', 11: 'Budget V3', 12: 'LY - Actual'},
            'MAR': {13: 'Realizado', 14: 'Budget V1', 16: 'Budget V3', 17: 'LY - Actual'},
            'ABR': {18: 'Realizado', 19: 'Budget V1', 21: 'Budget V3', 22: 'LY - Actual'},
            'MAI': {23: 'Realizado', 24: 'Budget V1', 26: 'Budget V3', 27: 'LY - Actual'},
            'JUN': {28: 'Realizado', 29: 'Budget V1', 31: 'Budget V3', 32: 'LY - Actual'},
            'JUL': {33: 'Realizado', 34: 'Budget V1', 36: 'Budget V3', 37: 'LY - Actual'},
            'AGO': {38: 'Realizado', 39: 'Budget V1', 41: 'Budget V3', 42: 'LY - Actual'},
            'SET': {43: 'Realizado', 44: 'Budget V1', 46: 'Budget V3', 47: 'LY - Actual'},
            'OUT': {48: 'Realizado', 49: 'Budget V1', 51: 'Budget V3', 52: 'LY - Actual'},
            'NOV': {53: 'Realizado', 54: 'Budget V1', 56: 'Budget V3', 57: 'LY - Actual'},
            'DEZ': {58: 'Realizado', 59: 'Budget V1', 61: 'Budget V3', 62: 'LY - Actual'}
        }
        
        lista_dfs_meses = []
        for mes, mapa_indices in mapa_colunas_mes.items():
            cols_id_existentes = [col for col in colunas_identificadoras if col in df_processado.columns]
            cols_idx_existentes = [df_processado.columns[i] for i in mapa_indices.keys() if i < len(df_processado.columns)]
            
            df_mes_temp = df_processado[cols_id_existentes + cols_idx_existentes].copy()
            mapa_rename = {df_processado.columns[i]: nome_final for i, nome_final in mapa_indices.items() if i < len(df_processado.columns)}
            df_mes_temp.rename(columns=mapa_rename, inplace=True)
            df_mes_temp['mes'] = mes
            
            value_vars_existentes = [v for v in mapa_rename.values() if v in df_mes_temp.columns]
            id_vars_melt = cols_id_existentes + ['mes']
            
            df_melted = df_mes_temp.melt(id_vars=id_vars_melt, value_vars=value_vars_existentes, var_name='tipo_valor', value_name='valor')
            lista_dfs_meses.append(df_melted)
        
        if lista_dfs_meses:
            df_pl = pd.concat(lista_dfs_meses, ignore_index=True)
            df_pl['mes_num'] = df_pl['mes'].map(MESES_NUM_MAP)
            df_pl['ano'] = ano
            df_pl['data'] = pd.to_datetime(dict(year=df_pl['ano'], month=df_pl['mes_num'], day=1))
            df_pl['valor'] = pd.to_numeric(df_pl['valor'], errors='coerce').fillna(0)
    except Exception as e:
        st.error(f"Erro ao processar P&L: {e}")
        df_pl = pd.DataFrame()

    # -------------------------------------------------------------------------
    # 2. PROCESSAR RAZ√ÉO DE GASTOS
    # -------------------------------------------------------------------------
    df_razao = pd.DataFrame()
    try:
        if hasattr(uploaded_file, 'seek'): uploaded_file.seek(0)
        try:
            df_r = pd.read_excel(uploaded_file, sheet_name='Raz√£o_Gastos', header=1)
            
            df_r = _standardize_columns(df_r)
            RENAME_MAP = {'valor_credito': 'valor', 'nome_do_fornecedor': 'fornecedor'}
            df_r.rename(columns=RENAME_MAP, inplace=True)
            
            if 'centro_gasto' in df_r.columns:
                df_r.rename(columns={'centro_gasto': 'codigo_centro_gasto'}, inplace=True)
                df_r['codigo_centro_gasto'] = df_r['codigo_centro_gasto'].astype(str).str.replace(r'\.0$', '', regex=True)
                df_r['codigo_centro_gasto'] = df_r['codigo_centro_gasto'].apply(lambda x: '0' + x if len(x) == 10 else x)
                df_r['centro_gasto_nome'] = df_r['codigo_centro_gasto'].map(mapa_centro_custo) # Reusing map from P&L scope if compatible or redefine
            else:
                df_r['centro_gasto_nome'] = 'N/A'
                
            if 'valor' in df_r.columns:
                df_r['valor'] = pd.to_numeric(df_r['valor'], errors='coerce').fillna(0)
            else:
                df_r['valor'] = 0
                
            if 'fornecedor' not in df_r.columns: df_r['fornecedor'] = 'N/A'
            
            df_razao = df_r
            
            # --- PERSIST√äNCIA NA TABELA RAZAO_REALIZADO ---
            try:
                if not df_razao.empty:
                    session = get_session()
                    try:
                        # Limpar dados deste ano para evitar duplica√ß√£o (Shadow Ledger deve espelhar o √∫ltimo upload)
                        session.query(RazaoRealizado).filter(RazaoRealizado.ano == ano).delete()
                        
                        registros = []
                        # Identificar coluna de data
                        col_data = next((c for c in df_razao.columns if 'data' in c.lower() or 'dt' in c.lower()), None)
                        col_historico = next((c for c in df_razao.columns if 'historico' in c.lower() or 'descri' in c.lower()), 'descricao')
                        col_conta = next((c for c in df_razao.columns if 'conta' in c.lower()), 'conta_contabil')

                        for _, row in df_razao.iterrows():
                            # Extrair Data e M√™s
                            mes_str = 'N/A'
                            data_lanc = None
                            
                            if col_data and pd.notna(row[col_data]):
                                try:
                                    dt = pd.to_datetime(row[col_data], dayfirst=True)
                                    data_lanc = dt
                                    # Pega o m√™s pelo √≠ndice (1=JAN, etc)
                                    mes_idx = dt.month - 1
                                    if 0 <= mes_idx < 12:
                                        from utils_financeiro import MESES_ORDEM # Garantir escopo ou usar global
                                        # MESES_ORDEM j√° est√° no modulo, mas por seguran√ßa:
                                        meses = ['JAN', 'FEV', 'MAR', 'ABR', 'MAI', 'JUN', 'JUL', 'AGO', 'SET', 'OUT', 'NOV', 'DEZ']
                                        mes_str = meses[mes_idx]
                                except: pass
                            
                            reg = RazaoRealizado(
                                ano=ano,
                                mes=mes_str,
                                centro_gasto_codigo=str(row.get('codigo_centro_gasto', '')),
                                conta_contabil_codigo=str(row.get(col_conta, '')),
                                fornecedor=str(row.get('fornecedor', '')),
                                descricao=str(row.get(col_historico, '')),
                                valor=float(row.get('valor', 0)),
                                data_lancamento=data_lanc
                            )
                            registros.append(reg)
                        
                        if registros:
                            session.add_all(registros)
                            session.commit()
                    except Exception as e_db:
                        session.rollback()
                        print(f"Erro ao salvar Raz√£o no banco: {e_db}")
                    finally:
                        session.close()
            except Exception as e:
                print(f"Erro geral na persist√™ncia do Raz√£o: {e}")
            
        except ValueError:
            # Aba n√£o encontrada, n√£o √© erro cr√≠tico, apenas retorna vazio
            pass
            
    except Exception as e:
        st.error(f"Erro ao processar Raz√£o: {e}")

    return df_pl, df_razao


@st.cache_data(show_spinner="Processando aba de or√ßamento...")
def processar_aba_orcamento(
    uploaded_file,
    sheet_name: str,
    ano_referencia: int = 2025
) -> pd.DataFrame:
    # ... c√≥digo mantido, s√≥ para garantir integridade do replace ...
    # Mas como 'processar_pl_baseal' termina na 228, e eu estou substituindo at√© a 1323...
    # PERA√ç, EU N√ÉO POSSO SUBSTITUIR O ARQUIVO INTEIRO DE 88 A 1323. √â MUITO C√ìDIGO.
    # Vou fazer replaces menores.
    pass

# FIM DA TENTATIVA ERRADA. N√ÉO SUBMETER ISSO.



@st.cache_data(show_spinner="Processando Raz√£o de Gastos...")
def processar_razao_gastos(uploaded_file) -> pd.DataFrame:
    """
    Processa a aba 'Raz√£o_Gastos'
    (Vers√£o completa do 'utils - old.py' fornecida pelo usu√°rio)
    """
    if not uploaded_file:
        return pd.DataFrame()
    try:
        # Tenta ler a aba espec√≠fica. Se n√£o existir, retorna DF vazio.
        try:
            df = pd.read_excel(uploaded_file, sheet_name='Raz√£o_Gastos', header=1)
        except ValueError:
            st.sidebar.warning("Aba 'Raz√£o_Gastos' n√£o encontrada no arquivo P&L.")
            return pd.DataFrame()
            
        df = _standardize_columns(df)
        
        RENAME_MAP = {
            'valor_credito': 'valor', # Padronizado de 'VALOR CR√âDITO'
            'nome_do_fornecedor': 'fornecedor' # Padronizado de 'Nome do Fornecedor'
            # Adicionar outros mapeamentos se necess√°rio
        }
        df.rename(columns=RENAME_MAP, inplace=True)
        
        # Processa centro de gasto se a coluna existir (padronizado de 'CENTRO GASTO')
        if 'centro_gasto' in df.columns:
            df.rename(columns={'centro_gasto': 'codigo_centro_gasto'}, inplace=True)
            df['codigo_centro_gasto'] = df['codigo_centro_gasto'].astype(str).str.replace(r'\.0$', '', regex=True)
            df['codigo_centro_gasto'] = df['codigo_centro_gasto'].apply(lambda x: '0' + x if len(x) == 10 else x)
            
            # Mapa de centro de custo (o mesmo do P&L)
            mapa_centro_custo = {
                '01020504001': 'Ger√™ncia Regional BA', '1020504001': 'Ger√™ncia Regional BA',
                '01020504101': 'Coordena√ß√£o Catu', '1020504101': 'Coordena√ß√£o Catu',
                '01020504102': 'ECOMP CATU - BA', '1020504102': 'ECOMP CATU - BA',
                '01020504204': 'BASE CATU - BA', '1020504204': 'BASE CATU - BA',
                '01020504201': 'Coordena√ß√£o Estacion√°rio BA', '1020504201': 'Coordena√ß√£o Estacion√°rio BA',
                '01020504202': 'BASE CAMA√áARI - BA', '1020504202': 'BASE CAMA√áARI - BA',
                '01020504203': 'BASE ITABUNA - BA', '1020504203': 'BASE ITABUNA - BA',
                '01020505201': 'Coordena√ß√£o Estacionar SE/AL', '1020505201': 'Coordena√ß√£o Estacionar SE/AL',
                '01020505202': 'BASE ATALAIA - SE', '1020505202': 'BASE ATALAIA - SE',
                '01020505203': 'BASE PILAR - AL', '1020505203': 'BASE PILAR - AL'
            }
            df['centro_gasto_nome'] = df['codigo_centro_gasto'].map(mapa_centro_custo)
        else:
            st.warning("Raz√£o: Coluna 'centro_gasto' n√£o encontrada. An√°lise por centro de custo pode falhar.")
            df['centro_gasto_nome'] = 'N/A' # Cria coluna para evitar erros

        # Garante que a coluna 'valor' exista
        if 'valor' in df.columns:
            df['valor'] = pd.to_numeric(df['valor'], errors='coerce').fillna(0)
        else:
            st.warning("Raz√£o: Coluna 'valor' (de 'valor_credito') n√£o encontrada. Gastos de fornecedores ser√£o zero.")
            df['valor'] = 0 
            
        # Garante que a coluna 'fornecedor' exista
        if 'fornecedor' not in df.columns:
             st.warning("Raz√£o: Coluna 'fornecedor' (de 'nome_do_fornecedor') n√£o encontrada.")
             df['fornecedor'] = 'N/A'
             
        return df

    except Exception as e:
        st.error(f"Erro cr√≠tico ao processar a aba 'Raz√£o_Gastos': {e}")
        return pd.DataFrame()



# =============================================================================
# 4. VALIDA√á√ÉO DE DADOS (PANDERA)
# =============================================================================

# Schema para P&L
SCHEMA_PL = DataFrameSchema(
    columns={
        'codigo_centro_gasto': Column(str, nullable=True, coerce=True),
        'centro_gasto_nome': Column(str, nullable=True, coerce=True),
        'conta_contabil': Column(str, nullable=False, coerce=True),
        'mes': Column(str, checks=[Check.isin(MESES_ORDEM)], nullable=False, coerce=True),
        'tipo_valor': Column(
            str, 
            checks=[Check.isin(['Realizado', 'Budget V1', 'Budget V3', 'LY - Actual'])], 
            nullable=False, 
            coerce=True
        ),
        'valor': Column(float, checks=[Check.greater_than_or_equal_to(0)], nullable=False, coerce=True),
        'ano': Column(int, checks=[Check.in_range(2000, datetime.now().year + 5)], nullable=False, coerce=True),
        'data': Column(pa.DateTime, nullable=False, coerce=True)
    },
    strict=False,
    coerce=True
)

class ValidadorDados:
    """Validador de dados financeiros usando Pandera."""
    
    def __init__(self):
        self.schemas = {
            'pl': SCHEMA_PL
        }
    
    def _formatar_erros(self, schema_errors: pa.errors.SchemaErrors) -> List[Dict]:
        """Formata erros do Pandera para exibi√ß√£o."""
        erros_detalhados = []
        if schema_errors.failure_cases is not None and not schema_errors.failure_cases.empty:
            for erro in schema_errors.failure_cases.itertuples():
                erros_detalhados.append({
                    'coluna': getattr(erro, 'column', 'DataFrame'),
                    'check': getattr(erro, 'check', 'N/A'),
                    'index': getattr(erro, 'index', 'N/A'),
                    'valor_falha': getattr(erro, 'failure_case', 'N/A')
                })
        return erros_detalhados
    
    def validar_pl(self, df: pd.DataFrame, lazy: bool = True) -> Tuple[bool, Optional[pd.DataFrame], Dict]:
        """Valida DataFrame de P&L."""
        try:
            df_validado = self.schemas['pl'].validate(df, lazy=lazy)
            relatorio = {
                'status': 'SUCESSO',
                'total_linhas': len(df),
                'linhas_validas': len(df_validado),
                'erros': []
            }
            return True, df_validado, relatorio
        except pa.errors.SchemaErrors as e:
            erros_fmt = self._formatar_erros(e)
            relatorio = {
                'status': 'FALHA',
                'total_linhas': len(df),
                'linhas_com_erro': len(e.failure_cases) if e.failure_cases is not None else 1,
                'erros': erros_fmt
            }
            return False, None, relatorio


# =============================================================================
# 5. VISUALIZA√á√ïES AVAN√áADAS
# =============================================================================





# =============================================================================
# 4. VALIDA√á√ÉO DE DADOS (PANDERA)
# =============================================================================

# Schema para P&L
SCHEMA_PL = DataFrameSchema(
    columns={
        'codigo_centro_gasto': Column(str, nullable=True, coerce=True),
        'centro_gasto_nome': Column(str, nullable=True, coerce=True),
        'conta_contabil': Column(str, nullable=False, coerce=True),
        'mes': Column(str, checks=[Check.isin(MESES_ORDEM)], nullable=False, coerce=True),
        'tipo_valor': Column(
            str, 
            checks=[Check.isin(['Realizado', 'Budget V1', 'Budget V3', 'LY - Actual'])], 
            nullable=False, 
            coerce=True
        ),
        'valor': Column(float, checks=[Check.greater_than_or_equal_to(0)], nullable=False, coerce=True),
        'ano': Column(int, checks=[Check.in_range(2000, datetime.now().year + 5)], nullable=False, coerce=True),
        'data': Column(pa.DateTime, nullable=False, coerce=True)
    },
    strict=False,
    coerce=True
)

# Schema para Or√ßamento
SCHEMA_ORCAMENTO = DataFrameSchema(
    columns={
        'base_operacional': Column(str, checks=[Check.isin(ABAS_PROCESSAR)], nullable=False, coerce=True),
        'fornecedor': Column(str, nullable=False, coerce=True),
        'servico_consumo': Column(str, nullable=False, coerce=True),
        'mes': Column(str, checks=[Check.isin(MESES_ORDEM)], nullable=False, coerce=True),
        'ano': Column(int, checks=[Check.in_range(2020, 2030)], nullable=False, coerce=True),
        'previsto': Column(float, checks=[Check.greater_than_or_equal_to(0)], nullable=False, coerce=True),
        'realizado': Column(float, checks=[Check.greater_than_or_equal_to(0)], nullable=False, coerce=True),
        'diferenca': Column(float, nullable=False, coerce=True),
        'data': Column(pa.DateTime, nullable=False, coerce=True)
    },
    strict=False,
    coerce=True
)


class ValidadorDados:
    """Validador de dados financeiros usando Pandera."""
    
    def __init__(self):
        self.schemas = {
            'pl': SCHEMA_PL,
            'orcamento': SCHEMA_ORCAMENTO
        }
    
    def _formatar_erros(self, schema_errors: pa.errors.SchemaErrors) -> List[Dict]:
        """Formata erros do Pandera para exibi√ß√£o."""
        erros_detalhados = []
        if schema_errors.failure_cases is not None and not schema_errors.failure_cases.empty:
            for erro in schema_errors.failure_cases.itertuples():
                erros_detalhados.append({
                    'coluna': getattr(erro, 'column', 'DataFrame'),
                    'check': getattr(erro, 'check', 'N/A'),
                    'index': getattr(erro, 'index', 'N/A'),
                    'valor_falha': getattr(erro, 'failure_case', 'N/A')
                })
        return erros_detalhados
    
    def validar_pl(self, df: pd.DataFrame, lazy: bool = True) -> Tuple[bool, Optional[pd.DataFrame], Dict]:
        """Valida DataFrame de P&L."""
        try:
            df_validado = self.schemas['pl'].validate(df, lazy=lazy)
            relatorio = {
                'status': 'SUCESSO',
                'total_linhas': len(df),
                'linhas_validas': len(df_validado),
                'erros': []
            }
            return True, df_validado, relatorio
        except pa.errors.SchemaErrors as e:
            erros_fmt = self._formatar_erros(e)
            relatorio = {
                'status': 'FALHA',
                'total_linhas': len(df),
                'linhas_com_erro': len(e.failure_cases) if e.failure_cases is not None else 1,
                'erros': erros_fmt
            }
            return False, None, relatorio
    
    def validar_orcamento(self, df: pd.DataFrame, lazy: bool = True) -> Tuple[bool, Optional[pd.DataFrame], Dict]:
        """Valida DataFrame de Or√ßamento."""
        try:
            if 'data' not in df.columns:
                if all(col in df.columns for col in ['ano', 'mes']):
                    df['mes_num'] = df['mes'].map(MESES_NUM_MAP)
                    df['data'] = pd.to_datetime(
                        dict(year=df['ano'], month=df['mes_num'], day=1),
                        errors='coerce'
                    )
                else:
                    raise ValueError("Colunas 'ano' e 'mes' necess√°rias para criar 'data'.")
            
            df_validado = self.schemas['orcamento'].validate(df, lazy=lazy)
            relatorio = {
                'status': 'SUCESSO',
                'total_linhas': len(df),
                'linhas_validas': len(df_validado),
                'erros': []
            }
            return True, df_validado, relatorio
        except (pa.errors.SchemaErrors, ValueError) as e:
            erros_fmt = self._formatar_erros(e) if isinstance(e, pa.errors.SchemaErrors) else [{'erro': str(e)}]
            relatorio = {
                'status': 'FALHA',
                'total_linhas': len(df),
                'linhas_com_erro': len(df),
                'erros': erros_fmt
            }
            return False, None, relatorio
    
    def gerar_relatorio_qualidade(self, df: pd.DataFrame) -> Dict:
        """Gera relat√≥rio de qualidade dos dados."""
        if df is None or df.empty:
            return {'colunas': {}}
        
        relatorio = {
            'timestamp': datetime.now().isoformat(),
            'total_linhas': len(df),
            'total_colunas': len(df.columns),
            'colunas': {}
        }
        
        for col in df.columns:
            stats_col = {
                'tipo': str(df[col].dtype),
                'valores_nulos': int(df[col].isna().sum()),
                'percentual_nulos': float(df[col].isna().sum() / len(df) * 100 if len(df) > 0 else 0),
                'valores_unicos': int(df[col].nunique())
            }
            
            if pd.api.types.is_numeric_dtype(df[col]):
                series_no_nan = df[col].dropna()
                stats_col.update({
                    'min': float(series_no_nan.min()) if not series_no_nan.empty else None,
                    'max': float(series_no_nan.max()) if not series_no_nan.empty else None,
                    'media': float(series_no_nan.mean()) if not series_no_nan.empty else None,
                    'mediana': float(series_no_nan.median()) if not series_no_nan.empty else None,
                    'desvio_padrao': float(series_no_nan.std()) if not series_no_nan.empty else None
                })
            
            relatorio['colunas'][col] = stats_col
        
        return relatorio


# =============================================================================
# 5. FUN√á√ïES DE ESTAT√çSTICAS E EXPORTA√á√ÉO
# =============================================================================

def gerar_estatisticas_orcamento(df: pd.DataFrame) -> Dict:
    """Gera estat√≠sticas do or√ßamento."""
    stats = {
        'total_previsto': df['previsto'].sum(),
        'total_realizado': df['realizado'].sum(),
        'percentual_execucao': (df['realizado'].sum() / df['previsto'].sum() * 100) if df['previsto'].sum() > 0 else 0,
        'desvios_criticos': len(df[abs(df['diferenca']) > (df['previsto'] * 0.2)])
    }
    return stats


def exportar_orcamento_csv(df: pd.DataFrame) -> str:
    """Exporta or√ßamento para CSV."""
    return df.to_csv(index=False).encode('utf-8')


# =============================================================================
# 6. VISUALIZA√á√ïES AVAN√áADAS
# =============================================================================

def plot_heatmap_desvios(df: pd.DataFrame) -> go.Figure:
    """Gera heatmap de desvios or√ßament√°rios."""
    df_heatmap = df.pivot_table(
        values='diferenca',
        index='base_operacional',
        columns='mes',
        aggfunc='sum'
    )
    df_heatmap = df_heatmap.reindex(columns=MESES_ORDEM)
    
    fig = go.Figure(data=go.Heatmap(
        z=df_heatmap.values,
        x=df_heatmap.columns,
        y=df_heatmap.index,
        colorscale='RdYlGn',
        zmid=0,
        text=df_heatmap.values,
        texttemplate='R$ %{text:.2f}',
        textfont={"size": 10},
        colorbar=dict(title="Desvio (R$)")
    ))
    
    fig.update_layout(
        title="Heatmap de Desvios Or√ßament√°rios por Base e M√™s",
        xaxis_title="M√™s",
        yaxis_title="Base Operacional",
        height=400
    )
    
    return fig


def plot_robust_forecast(df, date_col, value_col, periods=3):
    """
    Gera um gr√°fico de previs√£o robusto para s√©ries curtas (< 24 meses) ou longas.
    Usa Holt-Winters se poss√≠vel, ou Regress√£o Linear Simples se dados insuficientes.
    """
    try:
        df_proc = df.copy()
        df_proc[date_col] = pd.to_datetime(df_proc[date_col])
        df_proc = df_proc.sort_values(date_col).set_index(date_col)
        
        # Agrupar mensalmente para garantir regularidade
        ts = df_proc[value_col].resample('MS').sum().fillna(0)
        
        # Trabalhar com valores absolutos para evitar erros de log/multiplicativo com negativos
        ts_abs = ts.abs()
        was_negative = (ts.mean() < 0)
        
        df_plot = pd.DataFrame({'Realizado': ts_abs})
        
        # Previs√£o Simples (M√©dia M√≥vel Exponencial + Tend√™ncia Linear)
        # Se tivermos poucos dados (< 12), usamos apenas uma m√©dia simples projetada
        if len(ts) < 4:
            return None # Muito poucos dados
            
        # Estimativa de tend√™ncia linear simples
        from sklearn.linear_model import LinearRegression
        import numpy as np
        
        X = np.arange(len(ts)).reshape(-1, 1)
        y = ts_abs.values
        model = LinearRegression()
        model.fit(X, y)
        
        # Projetar futuro
        last_idx = len(ts)
        future_X = np.arange(last_idx, last_idx + periods).reshape(-1, 1)
        future_y = model.predict(future_X)
        
        # Criar datas futuras
        last_date = ts.index[-1]
        future_dates = [last_date + pd.DateOffset(months=i+1) for i in range(periods)]
        
        df_forecast = pd.DataFrame({'Previs√£o': future_y}, index=future_dates)
        
        # Unir para plot
        df_final = pd.concat([df_plot, df_forecast])
        
        # Reverter sinal se era despesa (negativo)
        if was_negative:
            df_final = df_final * -1
            
        fig = go.Figure()
        
        # S√©rie Realizada
        fig.add_trace(go.Scatter(
            x=df_final.index[:-periods], 
            y=df_final['Realizado'].iloc[:-periods],
            mode='lines+markers',
            name='Realizado',
            line=dict(color='#3b82f6', width=3)
        ))
        
        # S√©rie Previs√£o (Linha tracejada)
        fig.add_trace(go.Scatter(
            x=df_final.index[-periods-1:], # Conectar com √∫ltimo ponto real
            y=df_final['Realizado'].iloc[-periods-1:].fillna(0) + df_final['Previs√£o'].iloc[-periods-1:].fillna(0), # Truque para pegar ponta
            mode='lines+markers',
            name='Tend√™ncia Projetada',
            line=dict(color='#10b981', dash='dash', width=3)
        ))
        
        # Adicionar Previs√£o puramente (caso overlap falhe)
        fig.add_trace(go.Scatter(
             x=df_forecast.index,
             y=df_final['Previs√£o'].dropna(),
             mode='markers',
             name='Previs√£o',
             marker=dict(color='#10b981', size=8)
        ))

        fig.update_layout(
            title="Proje√ß√£o de Tend√™ncia (Linear)",
            xaxis_title="M√™s",
            yaxis_title="Valor (R$)",
            template="plotly_dark",
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
        )
        return fig
        
    except Exception as e:
        print(f"Erro na previs√£o: {e}")
        return Nonefig


# =============================================================================
# 7. INTEGRA√á√ÉO COM IA
# =============================================================================

def get_ai_chat_response(messages: List[Dict], api_key: str, provider: str) -> str:
    """
    Envia prompt para IA e retorna resposta.
    
    Args:
        messages: Lista de mensagens no formato [{"role": "user", "content": "..."}]
        api_key: Chave de API
        provider: "Gemini (Google)" ou "Copilot (OpenAI GPT-4)"
        
    Returns:
        Resposta da IA como string
    """
    try:
        if "Gemini" in provider:
            genai.configure(api_key=api_key)
            
            # Selecionar modelo (Padr√£o 3 Pro, fallback para 3 Flash se solicitado)
            model_name = 'gemini-3-pro-preview'
            if 'Flash' in provider:
                model_name = 'gemini-3-flash-preview'
            
            # print(f"[DEBUG] Usando Modelo: {model_name}")
            model = genai.GenerativeModel(model_name)
            
            # Concatenar mensagens
            prompt = "\n".join([msg["content"] for msg in messages if msg["role"] == "user"])
            response = model.generate_content(prompt)
            return response.text
        
        elif "OpenAI" in provider or "Copilot" in provider:
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4",
                messages=messages,
                temperature=0.7
            )
            return response.choices[0].message.content
        
        else:
            return "Provedor de IA n√£o reconhecido."
    
    except Exception as e:
        return f"Erro ao consultar IA: {e}"


def gerar_analise_ia(df: pd.DataFrame, api_key: str, provider: str, contexto: str = "") -> str:
    """Gera an√°lise financeira usando IA."""
    
    # Preparar resumo dos dados
    resumo = df.describe().to_string()
    
    prompt = f"""
    Voc√™ √© um analista financeiro s√™nior especializado em gest√£o de O&M de gasodutos.
    
    Contexto: {contexto}
    
    Analise os dados financeiros abaixo e forne√ßa:
    1. **Resumo Executivo** da performance financeira
    2. **Principais Insights** (top 3)
    3. **Recomenda√ß√µes Estrat√©gicas** (top 3)
    4. **Alertas e Riscos** identificados
    
    Dados:
    ```
    {resumo}
    ```
    
    Formate sua resposta em Markdown com emojis para melhor visualiza√ß√£o.
    """
    
    messages = [
        {"role": "system", "content": "Voc√™ √© um analista financeiro especialista em O&M de gasodutos."},
        {"role": "user", "content": prompt}
    ]
    
    return get_ai_chat_response(messages, api_key, provider)




# =============================================================================
# 8. FORECASTING MATEM√ÅTICO (STREAMLIT CLOUD COMPATIBLE)
# =============================================================================

class SimpleForecaster:
    """Modelo de forecasting matem√°tico usando extrapola√ß√£o linear e m√©dias m√≥veis."""
    
    def __init__(self):
        self.model = None
        self.forecast = None
        self.method = None
        self.historical_data = None
        self.confidence_intervals = None
        
    def fit(self, df: pd.DataFrame, date_col: str, value_col: str, method='hybrid', **kwargs):
        """
        Treina o modelo de forecasting.
        
        Args:
            df: DataFrame com dados hist√≥ricos
            date_col: Nome da coluna de data
            value_col: Nome da coluna de valores
            method: M√©todo de forecasting ('linear', 'sma', 'ema', 'seasonal', 'hybrid')
            **kwargs: Par√¢metros adicionais (window_size para m√©dias m√≥veis, etc.)
        """
        self.method = method
        self.date_col = date_col
        self.value_col = value_col
        
        # Ordenar por data
        df_sorted = df.sort_values(date_col).copy()
        self.historical_data = df_sorted
        
        # Armazenar s√©rie temporal
        self.dates = df_sorted[date_col].values
        self.values = df_sorted[value_col].values
        
        # Par√¢metros do modelo
        self.window_size = kwargs.get('window_size', 3)
        self.alpha = kwargs.get('alpha', 0.3)  # Para EMA
        
    def _linear_trend(self, periods: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Calcula tend√™ncia linear usando regress√£o."""
        X = np.arange(len(self.values)).reshape(-1, 1)
        y = self.values
        
        # Regress√£o linear
        model = LinearRegression()
        model.fit(X, y)
        
        # Previs√µes futuras
        future_X = np.arange(len(self.values), len(self.values) + periods).reshape(-1, 1)
        predictions = model.predict(future_X)
        
        # Intervalo de confian√ßa baseado em desvio padr√£o dos res√≠duos
        residuals = y - model.predict(X)
        std_residuals = np.std(residuals)
        lower = predictions - 1.96 * std_residuals
        upper = predictions + 1.96 * std_residuals
        
        return predictions, lower, upper
    
    def _moving_average(self, periods: int, ma_type='sma') -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Calcula m√©dias m√≥veis (Simple ou Exponential)."""
        if ma_type == 'sma':
            # Simple Moving Average
            last_values = self.values[-self.window_size:]
            prediction = np.mean(last_values)
            predictions = np.full(periods, prediction)
        else:
            # Exponential Moving Average
            ema = self.values[0]
            for val in self.values[1:]:
                ema = self.alpha * val + (1 - self.alpha) * ema
            predictions = np.full(periods, ema)
        
        # Intervalo de confian√ßa baseado em desvio padr√£o
        std_values = np.std(self.values)
        lower = predictions - 1.96 * std_values
        upper = predictions + 1.96 * std_values
        
        return predictions, lower, upper
    
    def _seasonal_decompose(self, periods: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Decomposi√ß√£o sazonal + extrapola√ß√£o de tend√™ncia."""
        # Preparar s√©rie temporal
        df_ts = self.historical_data.set_index(self.date_col)[self.value_col]
        
 # Decomposi√ß√£o
        try:
            decomposition = seasonal_decompose(df_ts, model='additive', period=min(12, len(df_ts)//2), extrapolate_trend='freq')
            
            # Extrair componentes
            trend = decomposition.trend.dropna()
            seasonal = decomposition.seasonal.dropna()
            
            # Extrapolar tend√™ncia linearmente
            X_trend = np.arange(len(trend)).reshape(-1, 1)
            model = LinearRegression()
            model.fit(X_trend, trend.values)
            
            future_X = np.arange(len(trend), len(trend) + periods).reshape(-1, 1)
            future_trend = model.predict(future_X)
            
            # Repetir padr√£o sazonal
            seasonal_pattern = seasonal.values[-12:] if len(seasonal) >= 12 else seasonal.values
            future_seasonal = np.tile(seasonal_pattern, (periods // len(seasonal_pattern) + 1))[:periods]
            
            # Combinar
            predictions = future_trend + future_seasonal
            
            # Intervalo de confian√ßa
            residuals = decomposition.resid.dropna()
            std_residuals = np.std(residuals)
            lower = predictions - 1.96 * std_residuals
            upper = predictions + 1.96 * std_residuals
            
        except Exception as e:
            # Fallback para tend√™ncia linear simples
            predictions, lower, upper = self._linear_trend(periods)
        
        return predictions, lower, upper
    
    def _hybrid_forecast(self, periods: int) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """Combina tend√™ncia linear com sazonalidade."""
        # Tend√™ncia linear
        linear_pred, _, _ = self._linear_trend(periods)
        
        # Componente sazonal
        try:
            df_ts = self.historical_data.set_index(self.date_col)[self.value_col]
            decomposition = seasonal_decompose(df_ts, model='additive', period=min(12, len(df_ts)//2), extrapolate_trend='freq')
            seasonal = decomposition.seasonal.dropna()
            
            # Repetir padr√£o sazonal
            seasonal_pattern = seasonal.values[-12:] if len(seasonal) >= 12 else seasonal.values
            future_seasonal = np.tile(seasonal_pattern, (periods // len(seasonal_pattern) + 1))[:periods]
            
            # Combinar
            predictions = linear_pred + future_seasonal
            
            # Intervalo de confian√ßa
            residuals = decomposition.resid.dropna()
            std_residuals = np.std(residuals)
            lower = predictions - 1.96 * std_residuals
            upper = predictions + 1.96 * std_residuals
            
        except Exception:
            # Fallback para tend√™ncia linear
            predictions, lower, upper = self._linear_trend(periods)
        
        return predictions, lower, upper
    
    def predict(self, periods: int = 12) -> pd.DataFrame:
        """
        Gera previs√µes futuras.
        
        Args:
            periods: N√∫mero de per√≠odos a prever
            
        Returns:
            DataFrame com previs√µes e intervalos de confian√ßa
        """
        if self.method == 'linear':
            predictions, lower, upper = self._linear_trend(periods)
        elif self.method == 'sma':
            predictions, lower, upper = self._moving_average(periods, ma_type='sma')
        elif self.method == 'ema':
            predictions, lower, upper = self._moving_average(periods, ma_type='ema')
        elif self.method == 'seasonal':
            predictions, lower, upper = self._seasonal_decompose(periods)
        else:  # hybrid
            predictions, lower, upper = self._hybrid_forecast(periods)
        
        # Criar datas futuras
        last_date = pd.to_datetime(self.dates[-1])
        future_dates = pd.date_range(start=last_date + pd.DateOffset(months=1), periods=periods, freq='MS')
        
        # DataFrame de resultados
        self.forecast = pd.DataFrame({
            'data': future_dates,
            'previsao': predictions,
            'limite_inferior': lower,
            'limite_superior': upper
        })
        
        return self.forecast
    
    def plot(self, df_hist: pd.DataFrame, date_col: str, value_col: str) -> go.Figure:
        """Plota hist√≥rico e previs√µes."""
        fig = go.Figure()
        
        # Hist√≥rico
        fig.add_trace(go.Scatter(
            x=df_hist[date_col],
            y=df_hist[value_col],
            mode='lines+markers',
            name='Hist√≥rico',
            line=dict(color='#1f77b4', width=2),
            marker=dict(size=4)
        ))
        
        if self.forecast is not None:
            # Previs√£o
            fig.add_trace(go.Scatter(
                x=self.forecast['data'],
                y=self.forecast['previsao'],
                mode='lines+markers',
                name='Previs√£o',
                line=dict(color='#d62728', width=2, dash='dash'),
                marker=dict(size=6)
            ))
            
            # Intervalo de confian√ßa
            fig.add_trace(go.Scatter(
                x=self.forecast['data'],
                y=self.forecast['limite_superior'],
                mode='lines',
                name='IC Superior',
                line=dict(color='rgba(214, 39, 40, 0.3)', width=0),
                showlegend=False
            ))
            
            fig.add_trace(go.Scatter(
                x=self.forecast['data'],
                y=self.forecast['limite_inferior'],
                mode='lines',
                name='IC Inferior',
                line=dict(color='rgba(214, 39, 40, 0.3)', width=0),
                fill='tonexty',
                fillcolor='rgba(214, 39, 40, 0.2)',
                showlegend=True
            ))
        
        # Layout
        method_names = {
            'linear': 'Tend√™ncia Linear',
            'sma': 'M√©dia M√≥vel Simples',
            'ema': 'M√©dia M√≥vel Exponencial',
            'seasonal': 'Decomposi√ß√£o Sazonal',
            'hybrid': 'Modelo H√≠brido (Linear + Sazonal)'
        }
        
        fig.update_layout(
            title=f"Previs√£o Financeira - {method_names.get(self.method, 'Matem√°tico')}",
            xaxis_title="Data",
            yaxis_title="Valor (R$)",
            hovermode='x unified',
            height=500,
            template='plotly_white'
        )
        
        return fig


# =============================================================================
# 9. INTERFACE DE FORECASTING (COMPONENTIZADA)
# =============================================================================

def criar_interface_forecasting_simples():
    """Interface Streamlit para Forecasting Matem√°tico."""
    st.subheader("üìà Previs√£o Financeira (Modelo Matem√°tico)")
    
    st.info("üí° **Modelo otimizado para Streamlit Cloud**: Utiliza extrapola√ß√£o linear e m√©dias m√≥veis para previs√µes r√°pidas e interpret√°veis.")
    
    if 'pl_df' not in st.session_state or st.session_state.pl_df is None:
        st.warning("‚ö†Ô∏è Carregue os dados de P&L primeiro.")
        return
    
    df = st.session_state.pl_df
    df_custos = df[df['codigo_centro_gasto'] != 0].copy()
    df_realizado = df_custos[df_custos['tipo_valor'] == 'Realizado'].groupby('data')['valor'].sum().reset_index()
    
    if len(df_realizado) < 3:
        st.error("‚ùå Dados insuficientes para previs√£o. Necess√°rio pelo menos 3 per√≠odos.")
        return
    
    # Configura√ß√µes de previs√£o
    col1, col2, col3 = st.columns(3)
    
    with col1:
        method = st.selectbox(
            "M√©todo de Previs√£o",
            options=['hybrid', 'linear', 'sma', 'ema', 'seasonal'],
            format_func=lambda x: {
                'linear': 'üìà Tend√™ncia Linear',
                'sma': 'üìä M√©dia M√≥vel Simples',
                'ema': 'üìâ M√©dia M√≥vel Exponencial',
                'seasonal': 'üåä Decomposi√ß√£o Sazonal',
                'hybrid': 'üîÆ H√≠brido (Recomendado)'
            }[x],
            index=0
        )
    
    with col2:
        periods = st.number_input(
            "Per√≠odos a Prever (meses)",
            min_value=1,
            max_value=24,
            value=12,
            help="N√∫mero de meses futuros para prever"
        )
    
    with col3:
        if method in ['sma', 'ema']:
            if method == 'sma':
                window_size = st.number_input(
                    "Janela da M√©dia M√≥vel",
                    min_value=2,
                    max_value=12,
                    value=3,
                    help="N√∫mero de per√≠odos para calcular a m√©dia"
                )
            else:
                alpha = st.slider(
                    "Alpha (EMA)",
                    min_value=0.1,
                    max_value=0.9,
                    value=0.3,
                    step=0.1,
                    help="Peso dos valores mais recentes"
                )
    
    # Bot√£o de treinar
    if st.button("üöÄ Gerar Previs√£o", type="primary"):
        with st.spinner("Gerando previs√£o..."):
            try:
                forecaster = SimpleForecaster()
                
                # Par√¢metros
                kwargs = {}
                if method == 'sma':
                    kwargs['window_size'] = window_size
                elif method == 'ema':
                    kwargs['alpha'] = alpha
                
                # Treinar
                forecaster.fit(df_realizado, 'data', 'valor', method=method, **kwargs)
                forecast_df = forecaster.predict(periods=periods)
                
                # Salvar no session state
                st.session_state.simple_forecaster = forecaster
                st.session_state.simple_forecast = forecast_df
                
                st.success("‚úÖ Previs√£o gerada com sucesso!")
                
            except Exception as e:
                st.error(f"‚ùå Erro ao gerar previs√£o: {e}")
                return
    
    # Exibir resultados
    if 'simple_forecast' in st.session_state:
        st.divider()
        st.subheader("üìä Resultados da Previs√£o")
        
        # Gr√°fico
        fig = st.session_state.simple_forecaster.plot(df_realizado, 'data', 'valor')
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabela de previs√µes
        st.subheader("üìã Valores Previstos")
        
        df_display = st.session_state.simple_forecast.copy()
        df_display['data'] = df_display['data'].dt.strftime('%Y-%m')
        df_display['previsao'] = df_display['previsao'].apply(lambda x: f"R$ {x:,.2f}")
        df_display['limite_inferior'] = df_display['limite_inferior'].apply(lambda x: f"R$ {x:,.2f}")
        df_display['limite_superior'] = df_display['limite_superior'].apply(lambda x: f"R$ {x:,.2f}")
        
        df_display.columns = ['M√™s', 'Previs√£o', 'Limite Inferior (95%)', 'Limite Superior (95%)']
        
        st.dataframe(df_display, use_container_width=True, hide_index=True)
        
        # Estat√≠sticas
        st.subheader("üìà Estat√≠sticas")
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        
        previsao_media = st.session_state.simple_forecast['previsao'].mean()
        historico_media = df_realizado['valor'].mean()
        variacao = ((previsao_media - historico_media) / historico_media * 100) if historico_media != 0 else 0
        
        col_stat1.metric(
            "M√©dia Prevista",
            f"R$ {previsao_media:,.2f}",
            delta=f"{variacao:+.1f}%"
        )
        col_stat2.metric(
            "M√©dia Hist√≥rica",
            f"R$ {historico_media:,.2f}"
        )
        col_stat3.metric(
            "Total Previsto ({} meses)".format(periods),
            f"R$ {st.session_state.simple_forecast['previsao'].sum():,.2f}"
        )
        
        # Download
        st.divider()
        csv = st.session_state.simple_forecast.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="üì• Download Previs√µes (CSV)",
            data=csv,
            file_name=f"previsoes_{method}_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )


# =============================================================================
# 10. INTEGRA√á√ÉO COM NOVA UI (HOME REFACTORED)
# =============================================================================

def verificar_status_dados() -> Dict:
    """Verifica status dos dados no session_state."""
    status = {
        'orcamento_ok': False,
        'orcamento_linhas': 0,
        'pl_ok': False,
        'pl_data': None,
        'mes_atual': datetime.now().strftime('%b/%Y').upper()
    }
    
    # Or√ßamento (Tenta carregar se n√£o existir)
    if 'df_orc_proc' not in st.session_state:
        try:
            # Tentar carga autom√°tica default (opcional)
            pass
        except:
            pass

    if 'df_orc_proc' in st.session_state and not st.session_state['df_orc_proc'].empty:
        status['orcamento_ok'] = True
        status['orcamento_linhas'] = len(st.session_state['df_orc_proc'])
        
    if 'pl_df' in st.session_state and not st.session_state['pl_df'].empty:
        status['pl_ok'] = True
        try:
            max_date = st.session_state['pl_df']['data'].max()
            status['pl_data'] = max_date.strftime('%d/%m/%Y')
        except:
            status['pl_data'] = "Data Desconhecida"
            
    return status

def processar_upload_pl(uploaded_file, ano: int = None) -> Tuple[bool, str, Dict]:
    """
    Wrapper para processar upload de P&L com valida√ß√£o.
    Suporta m√∫ltiplos anos via merge no session_state.
    Tamb√©m processa e armazena Raz√£o de Gastos.
    """
    if not uploaded_file:
        return False, "Nenhum arquivo enviado", {}
    
    if ano is None:
        ano = datetime.now().year
        
    try:
        # Processar com o ano informado usando a nova fun√ß√£o unificada
        df, df_razao = processar_upload_completo(uploaded_file, ano=ano)
        
        if not df.empty:
            # --- L√≥gica de Merge do P&L no Session State ---
            if 'pl_df' not in st.session_state or st.session_state['pl_df'] is None:
                st.session_state['pl_df'] = df
            else:
                # Remover dados existentes DESSE ano para evitar duplica√ß√£o
                df_existente = st.session_state['pl_df']
                if 'ano' in df_existente.columns:
                    df_existente = df_existente[df_existente['ano'] != ano]
                
                # Concatenar
                st.session_state['pl_df'] = pd.concat([df_existente, df], ignore_index=True)
            
            # --- L√≥gica de Persist√™ncia do Raz√£o ---
            # Para o Raz√£o, assumimos que o upload substitui ou adiciona. 
            # Como o Raz√£o √© auxiliar, vamos simplificar: Substituir ou adicionar a lista?
            # Melhor: Substituir o Raz√£o atual pelo novo upload (assumindo que o usu√°rio carrega o arquivo completo do m√™s/ano)
            # Mas se ele carregar 2024 e depois 2025? Precisamos talvez guardar por ano?
            # Por simplifica√ß√£o nesta fase: Armazenamos o √∫ltimo carregado ou tentamos conciliar.
            # Vamos armazenar o do √∫ltimo upload por enquanto, ou melhor, adicionar ao session_state['razao_df'] se n√£o existir, 
            # ou substituir se for do mesmo contexto.
            # DECIS√ÉO: Sobrescrever st.session_state['razao_df'] para garantir consist√™ncia com o arquivo carregado
            st.session_state['razao_df'] = df_razao
            
            # Gerar resumo acumulado
            df_atual = st.session_state['pl_df']
            anos_carregados = sorted(df_atual['ano'].unique().tolist()) if 'ano' in df_atual.columns else [ano]
            
            resumo = {
                'total_registros_pl': len(df_atual),
                'total_registros_razao': len(df_razao) if not df_razao.empty else 0,
                'anos': anos_carregados,
                'meses_por_ano': df_atual.groupby('ano')['mes'].nunique().to_dict(),
                'total_realizado': f"R$ {df_atual[df_atual['tipo_valor']=='Realizado']['valor'].sum():,.2f}"
            }
            st.session_state['pl_resumo_importacao'] = resumo
            
            msg_razao = " (+ Raz√£o)" if not df_razao.empty else ""
            return True, f"Importa√ß√£o de {ano} conclu√≠da{msg_razao}. Anos carregados: {anos_carregados}", resumo
        else:
            return False, "Falha ao processar arquivo P&L. Verifique o formato.", {}
    except Exception as e:
        return False, f"Erro ao processar: {e}", {}

def get_resumo_importacao():
    """Retorna resumo da √∫ltima importa√ß√£o."""
    return st.session_state.get('pl_resumo_importacao', {})

